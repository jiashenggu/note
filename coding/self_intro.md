Hi, I'm Jiasheng Gu. At 01.ai, I engineered the end-to-end training pipeline for proprietary VLMs (Vision-Language Models) and LLMs (Large Language Models), including 25B-A3.5B and 247B-A22B MoE models, to build a generative AI video product from scratch.

My work covered the full training spectrum: I managed the continued pre-training on a 20-billion-token dataset using Megatron-LM, and then implemented a two-stage SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization) fine-tuning process. It improved models' video understanding and captioning capabilities the product required.

I'm thrilled about this opportunity because I am deeply interested in robotic foundation models, and my background in training models for video perception and reasoning aligns directly with the challenges in robotics. I believe my experience will enable me to contribute significantly to the development of foundation models for Project GR00T.
