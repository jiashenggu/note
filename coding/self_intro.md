Hi, I'm Jiasheng Gu. At 01.ai, I engineered the end-to-end training pipeline for proprietary VLMs (Vision-Language Models) and LLMs (Large Language Models), including 25B-A3.5B and 247B-A22B MoE models, to build a generative AI video editing and mixing product from scratch.

My work covered the full training spectrum: I executed the continued pre-training on a 20-billion-token dataset using Megatron-LM, and then implemented a two-stage fine-tuning process involving SFT (Supervised Fine-Tuning) and DPO (Direct Preference Optimization). This enhanced the models' video understanding capabilities and enabled intelligent clipping, which were critical for the product.

I'm thrilled about this opportunity because I am deeply interested in robotic foundation models, and my background in training models for video perception and reasoning aligns directly with the challenges in robotics. I believe my experience will enable me to contribute significantly to the development of foundation models for Project GR00T.
